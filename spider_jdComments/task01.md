写这个爬虫程序真的是废了我好长一段时间，一开始选择的方法是用request库里面的get直接爬取内容，但是一开始发现自己的代码里面总有惊人数量的红色和橙色叹号，
比如说，爬取出的内容的格式不正确，甚至哥们一开始连要爬取的内容所在的json文件都找不到。
在看了b站大学的网课，看了别人的爬虫代码，以及我hxd的帮助下，哥们总算把代码写成了编译器能看得懂的样子，结果第一次运行，爬取了6页后，程序就自行终止了。

**现在我才知道，原来有一种东西叫做反爬，令人感叹。**

于是我开始又一轮查资料，并找了一个ip代理网站，花了十块钱(肉疼啊)买了一个代理池，但是这个
池子质量太低了，无效IP太多了，再加上我下水道级别的水平，导致我的代码又出现了新的不知如何解决的问题，
哥们的爬取任务又失败了。

摆烂了一周后，我又开始做这个任务，这次我选择使用selenium来控制浏览器模拟点击
以爬取页面，这种方式比之前直接爬取来的方便很多，只要控制好程序休眠的时间，就完全不用管
反爬的干扰，而且在分析好网页结构后，
所需的代码量比之前要花很多精力反反爬少很多，结构也更清晰，唯一的缺点就是爬取大量页面时效率略显低下。

不管怎么说，总算完成了第一个任务，看着控制台上面一页页的爬取进度，心里还是有抑制不住的欣喜。